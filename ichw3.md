# 通用高速缓存存储器工作原理及结构
## 1.工作原理
###### 又称cache，是位于CPU与内存之间的容量较小但速度很快的存储器，可保存CPU刚使用过或循环使用的部分数据，如果CPU需要再次使用该数据，那么就不用从内存重新调动该部分数据而是从cache中直接调用，这样就避免了重复存取数据，降低了CPU等待时间，提高了系统效率。（缓解处理数据的两端速度不匹配带来的时间上的浪费）
![cache](https://github.com/titina0729/ichw/blob/master/1.png)
###### cache的工作原理是基于程序访问的局部性。对大量的典型程序运行情况的分析结果表明，由程序产生的地址往往集中在存储逻辑地址空间很小的范围内，指令地址的分布本来就是连续的，加上循环程序段和子程序段要重复执行多次，因此对这些地址的访问就自然而然具有时间上的集中分布的特点。虽然数据的集中性并没有程序的集中性那么明显，但是对数组的访问及工作单元的选择都可以让存储器地址相对比较集中，这种局部范围的存储器地址频繁访问，对该范围以外的地址访问比较少的现象就被称为程序访问的局部性。那么根据程序访问的局部性原理，我们可以在CPU与内存之间设置一个高速的容量较小的存储器，把正在执行的指令地址附近的一部分指令或者数据从内存调到该存储器中，供CPU在这段时间内使用，这对提高程序的运行速度由很大的帮助。系统依据该原理，不断将与当前指令相关的不太大的后续指令从内存读到cache中来，然后再与CPU高速传送，从而达到速度匹配。

## 2.结构
![cache基本结构](https://github.com/titina0729/ichw/blob/master/cache基本结构.png)
###### cache的结构与内存相似，由地址和内容组成，但是不同于内存的是，cache line中包含着tag，valid以及data三个部分，也就是说，cache所储存的内容不仅有data（数据），还有相应的内容在内存中的地址信息（tag），除此之外为了加快寻找速度，一般还包含着一个有效位（valid）用来标记该cache line是否包含着有效的数据。一个tag，一个valid和一个data构成了一个cache line。而这些cache line 构成了cache。
#### cache有三种基本结构：
#### 1.DCACHE
由cache与write-buffer组成，后者是向前者写的缓冲处理器。
#### 2.ICACHE
#### 3.虚拟CACHE
又称逻辑CACHE,位于MMU前面靠近CPU。



## 3.除此之外的补充
#### 1.地址映射
cache的容量很小，其能够保存的内容只是内存内容的一个子集，且cache与主存的数据交换是以块为单位的，为了把信息放到cache中，要利用到映射的原理，将内存地址定位到cache当中，这就被称为地址映射。
##### A.直接映射
![直接映射](https://github.com/titina0729/ichw/blob/master/直接映射.gif)
###### 主存中的一个块只能映射到cache当中的某一个特定的块中。e.g.主存中第0块、第16块、……、第2032块，只能映射到cache的第0块，而主存的第1块、第17块、第2033块只能映射到cache的第1块……。
###### 直接映射是最简单的映射方法，它的硬件简单，成本低，地址变换速度块，而且不涉及替换算法问题。但是这种方式不够灵活，cache的存储空间得不到充分的利用，每个主存块只有一个固定位置可以存放，容易产生冲突导致命中率下降，效率下降，只适合大容量的cache。
##### B.全相联映射
![全相联映射](https://github.com/titina0729/ichw/blob/master/全相联映射.gif)
###### 主存中任何一块都可以映射到cache中的任意一个位置上。
###### 全相联映射方式比较灵活，cache的利用率高，但是硬件上的实现比较困难，因此只适合于小容量的cache。
##### C.组相连映射
![组相联映射](https://github.com/titina0729/ichw/blob/master/组相联映射.gif)
###### 是直接映射与全相联映射的折中方案，其将主存和cache分别分组，主存块存放在哪个组是固定的，但是存放在这个组的哪一块是灵活的，也就是主存中的各块与cache的组号之间有固定的映射联系，但可自由映射到对应cache组中的任意一块
######组相联结构cache是前两种方法的折中方案，适度兼顾二者的优点，尽量避免二者的缺点，因而得到普遍采用。

#### 2.替换
cache的工作原理要求其保存最新数据，当内存向cache传送一个新块，但cache的可用位置已经被占满时，就会产生cache替换的问题。替换问题与其组织方式紧密相关，对**直接映射cache**来说，只要把可用位置上的主存块患处cache即可；对全相联和组相联cache来说，要从若干个可用位置中国年选取一个位置，将其中的主存块换出cache。常用的替换算法有以下三种

#### 3.与主存保持一致
由于cache的内容知识主存内容的一个子集，应当与贮存内容保持，而CPU对cache的写入更改了cache的内容，为此，可选用操作策略使cache内容与贮存内容保持一致。
##### 1.写回法（Write-Back）
###### 当CPU写cache命中时，只修改cache的内容，而不是立即写入主存；只有当此块被换出时才被写回主存。
###### 这种方法显著减少了访问主存的次数，但是存在数据不一致的隐患。

##### 2.全写法（Write-Tthrough）
###### 当写cache命中时，cache与主存同时发生写修改。
###### cache与主存同步，较好维护了cache与贮存的内容一致性，但由于cache对CPU向主存的写操作没有高速缓冲功能，从而降低了cache的功效。
##### 3.写一次法（rite-Once）
###### 是基于写回法病结合全写法的操作策略，写命中与写为命中的处理方法与写回法基本相同，知识第一次命中要同时写入主存，以便于维护系统全部cache的一致性。

参考：
https://blog.csdn.net/baidu_35679960/article/details/78610804
http://share.onlinesjtu.com/mod/tab/view.php?id=206
https://blog.csdn.net/czxyhll/article/details/7960140
